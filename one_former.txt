backbone.patch_embed.projection.weight------>torch.Size([192, 3, 4, 4])
backbone.patch_embed.projection.bias------>torch.Size([192])
backbone.patch_embed.norm.weight------>torch.Size([192])
backbone.patch_embed.norm.bias------>torch.Size([192])
backbone.stages.0.blocks.0.norm1.weight------>torch.Size([192])
backbone.stages.0.blocks.0.norm1.bias------>torch.Size([192])
backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table------>torch.Size([529, 6])
backbone.stages.0.blocks.0.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.0.blocks.0.attn.w_msa.qkv.weight------>torch.Size([576, 192])
backbone.stages.0.blocks.0.attn.w_msa.qkv.bias------>torch.Size([576])
backbone.stages.0.blocks.0.attn.w_msa.proj.weight------>torch.Size([192, 192])
backbone.stages.0.blocks.0.attn.w_msa.proj.bias------>torch.Size([192])
backbone.stages.0.blocks.0.norm2.weight------>torch.Size([192])
backbone.stages.0.blocks.0.norm2.bias------>torch.Size([192])
backbone.stages.0.blocks.0.ffn.layers.0.0.weight------>torch.Size([768, 192])
backbone.stages.0.blocks.0.ffn.layers.0.0.bias------>torch.Size([768])
backbone.stages.0.blocks.0.ffn.layers.1.weight------>torch.Size([192, 768])
backbone.stages.0.blocks.0.ffn.layers.1.bias------>torch.Size([192])
backbone.stages.0.blocks.1.norm1.weight------>torch.Size([192])
backbone.stages.0.blocks.1.norm1.bias------>torch.Size([192])
backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table------>torch.Size([529, 6])
backbone.stages.0.blocks.1.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.0.blocks.1.attn.w_msa.qkv.weight------>torch.Size([576, 192])
backbone.stages.0.blocks.1.attn.w_msa.qkv.bias------>torch.Size([576])
backbone.stages.0.blocks.1.attn.w_msa.proj.weight------>torch.Size([192, 192])
backbone.stages.0.blocks.1.attn.w_msa.proj.bias------>torch.Size([192])
backbone.stages.0.blocks.1.norm2.weight------>torch.Size([192])
backbone.stages.0.blocks.1.norm2.bias------>torch.Size([192])
backbone.stages.0.blocks.1.ffn.layers.0.0.weight------>torch.Size([768, 192])
backbone.stages.0.blocks.1.ffn.layers.0.0.bias------>torch.Size([768])
backbone.stages.0.blocks.1.ffn.layers.1.weight------>torch.Size([192, 768])
backbone.stages.0.blocks.1.ffn.layers.1.bias------>torch.Size([192])
backbone.stages.0.downsample.norm.weight------>torch.Size([768])
backbone.stages.0.downsample.norm.bias------>torch.Size([768])
backbone.stages.0.downsample.reduction.weight------>torch.Size([384, 768])
backbone.stages.1.blocks.0.norm1.weight------>torch.Size([384])
backbone.stages.1.blocks.0.norm1.bias------>torch.Size([384])
backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table------>torch.Size([529, 12])
backbone.stages.1.blocks.0.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.1.blocks.0.attn.w_msa.qkv.weight------>torch.Size([1152, 384])
backbone.stages.1.blocks.0.attn.w_msa.qkv.bias------>torch.Size([1152])
backbone.stages.1.blocks.0.attn.w_msa.proj.weight------>torch.Size([384, 384])
backbone.stages.1.blocks.0.attn.w_msa.proj.bias------>torch.Size([384])
backbone.stages.1.blocks.0.norm2.weight------>torch.Size([384])
backbone.stages.1.blocks.0.norm2.bias------>torch.Size([384])
backbone.stages.1.blocks.0.ffn.layers.0.0.weight------>torch.Size([1536, 384])
backbone.stages.1.blocks.0.ffn.layers.0.0.bias------>torch.Size([1536])
backbone.stages.1.blocks.0.ffn.layers.1.weight------>torch.Size([384, 1536])
backbone.stages.1.blocks.0.ffn.layers.1.bias------>torch.Size([384])
backbone.stages.1.blocks.1.norm1.weight------>torch.Size([384])
backbone.stages.1.blocks.1.norm1.bias------>torch.Size([384])
backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table------>torch.Size([529, 12])
backbone.stages.1.blocks.1.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.1.blocks.1.attn.w_msa.qkv.weight------>torch.Size([1152, 384])
backbone.stages.1.blocks.1.attn.w_msa.qkv.bias------>torch.Size([1152])
backbone.stages.1.blocks.1.attn.w_msa.proj.weight------>torch.Size([384, 384])
backbone.stages.1.blocks.1.attn.w_msa.proj.bias------>torch.Size([384])
backbone.stages.1.blocks.1.norm2.weight------>torch.Size([384])
backbone.stages.1.blocks.1.norm2.bias------>torch.Size([384])
backbone.stages.1.blocks.1.ffn.layers.0.0.weight------>torch.Size([1536, 384])
backbone.stages.1.blocks.1.ffn.layers.0.0.bias------>torch.Size([1536])
backbone.stages.1.blocks.1.ffn.layers.1.weight------>torch.Size([384, 1536])
backbone.stages.1.blocks.1.ffn.layers.1.bias------>torch.Size([384])
backbone.stages.1.downsample.norm.weight------>torch.Size([1536])
backbone.stages.1.downsample.norm.bias------>torch.Size([1536])
backbone.stages.1.downsample.reduction.weight------>torch.Size([768, 1536])
backbone.stages.2.blocks.0.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.0.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.0.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.0.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.0.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.0.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.0.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.0.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.0.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.0.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.0.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.0.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.0.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.1.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.1.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.1.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.1.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.1.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.1.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.1.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.1.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.1.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.1.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.1.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.1.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.1.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.2.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.2.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.2.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.2.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.2.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.2.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.2.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.2.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.2.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.2.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.2.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.2.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.2.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.3.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.3.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.3.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.3.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.3.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.3.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.3.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.3.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.3.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.3.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.3.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.3.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.3.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.4.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.4.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.4.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.4.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.4.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.4.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.4.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.4.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.4.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.4.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.4.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.4.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.4.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.5.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.5.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.5.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.5.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.5.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.5.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.5.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.5.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.5.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.5.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.5.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.5.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.5.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.6.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.6.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.6.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.6.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.6.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.6.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.6.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.6.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.6.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.6.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.6.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.6.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.6.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.7.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.7.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.7.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.7.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.7.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.7.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.7.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.7.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.7.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.7.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.7.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.7.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.7.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.8.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.8.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.8.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.8.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.8.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.8.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.8.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.8.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.8.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.8.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.8.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.8.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.8.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.9.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.9.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.9.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.9.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.9.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.9.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.9.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.9.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.9.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.9.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.9.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.9.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.9.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.10.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.10.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.10.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.10.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.10.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.10.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.10.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.10.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.10.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.10.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.10.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.10.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.10.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.11.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.11.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.11.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.11.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.11.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.11.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.11.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.11.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.11.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.11.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.11.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.11.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.11.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.12.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.12.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.12.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.12.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.12.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.12.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.12.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.12.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.12.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.12.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.12.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.12.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.12.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.13.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.13.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.13.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.13.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.13.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.13.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.13.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.13.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.13.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.13.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.13.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.13.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.13.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.14.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.14.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.14.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.14.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.14.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.14.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.14.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.14.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.14.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.14.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.14.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.14.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.14.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.15.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.15.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.15.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.15.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.15.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.15.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.15.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.15.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.15.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.15.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.15.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.15.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.15.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.16.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.16.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.16.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.16.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.16.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.16.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.16.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.16.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.16.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.16.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.16.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.16.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.16.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.blocks.17.norm1.weight------>torch.Size([768])
backbone.stages.2.blocks.17.norm1.bias------>torch.Size([768])
backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table------>torch.Size([529, 24])
backbone.stages.2.blocks.17.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.2.blocks.17.attn.w_msa.qkv.weight------>torch.Size([2304, 768])
backbone.stages.2.blocks.17.attn.w_msa.qkv.bias------>torch.Size([2304])
backbone.stages.2.blocks.17.attn.w_msa.proj.weight------>torch.Size([768, 768])
backbone.stages.2.blocks.17.attn.w_msa.proj.bias------>torch.Size([768])
backbone.stages.2.blocks.17.norm2.weight------>torch.Size([768])
backbone.stages.2.blocks.17.norm2.bias------>torch.Size([768])
backbone.stages.2.blocks.17.ffn.layers.0.0.weight------>torch.Size([3072, 768])
backbone.stages.2.blocks.17.ffn.layers.0.0.bias------>torch.Size([3072])
backbone.stages.2.blocks.17.ffn.layers.1.weight------>torch.Size([768, 3072])
backbone.stages.2.blocks.17.ffn.layers.1.bias------>torch.Size([768])
backbone.stages.2.downsample.norm.weight------>torch.Size([3072])
backbone.stages.2.downsample.norm.bias------>torch.Size([3072])
backbone.stages.2.downsample.reduction.weight------>torch.Size([1536, 3072])
backbone.stages.3.blocks.0.norm1.weight------>torch.Size([1536])
backbone.stages.3.blocks.0.norm1.bias------>torch.Size([1536])
backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table------>torch.Size([529, 48])
backbone.stages.3.blocks.0.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.3.blocks.0.attn.w_msa.qkv.weight------>torch.Size([4608, 1536])
backbone.stages.3.blocks.0.attn.w_msa.qkv.bias------>torch.Size([4608])
backbone.stages.3.blocks.0.attn.w_msa.proj.weight------>torch.Size([1536, 1536])
backbone.stages.3.blocks.0.attn.w_msa.proj.bias------>torch.Size([1536])
backbone.stages.3.blocks.0.norm2.weight------>torch.Size([1536])
backbone.stages.3.blocks.0.norm2.bias------>torch.Size([1536])
backbone.stages.3.blocks.0.ffn.layers.0.0.weight------>torch.Size([6144, 1536])
backbone.stages.3.blocks.0.ffn.layers.0.0.bias------>torch.Size([6144])
backbone.stages.3.blocks.0.ffn.layers.1.weight------>torch.Size([1536, 6144])
backbone.stages.3.blocks.0.ffn.layers.1.bias------>torch.Size([1536])
backbone.stages.3.blocks.1.norm1.weight------>torch.Size([1536])
backbone.stages.3.blocks.1.norm1.bias------>torch.Size([1536])
backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table------>torch.Size([529, 48])
backbone.stages.3.blocks.1.attn.w_msa.relative_position_index------>torch.Size([144, 144])
backbone.stages.3.blocks.1.attn.w_msa.qkv.weight------>torch.Size([4608, 1536])
backbone.stages.3.blocks.1.attn.w_msa.qkv.bias------>torch.Size([4608])
backbone.stages.3.blocks.1.attn.w_msa.proj.weight------>torch.Size([1536, 1536])
backbone.stages.3.blocks.1.attn.w_msa.proj.bias------>torch.Size([1536])
backbone.stages.3.blocks.1.norm2.weight------>torch.Size([1536])
backbone.stages.3.blocks.1.norm2.bias------>torch.Size([1536])
backbone.stages.3.blocks.1.ffn.layers.0.0.weight------>torch.Size([6144, 1536])
backbone.stages.3.blocks.1.ffn.layers.0.0.bias------>torch.Size([6144])
backbone.stages.3.blocks.1.ffn.layers.1.weight------>torch.Size([1536, 6144])
backbone.stages.3.blocks.1.ffn.layers.1.bias------>torch.Size([1536])
backbone.norm0.weight------>torch.Size([192])
backbone.norm0.bias------>torch.Size([192])
backbone.norm1.weight------>torch.Size([384])
backbone.norm1.bias------>torch.Size([384])
backbone.norm2.weight------>torch.Size([768])
backbone.norm2.bias------>torch.Size([768])
backbone.norm3.weight------>torch.Size([1536])
backbone.norm3.bias------>torch.Size([1536])
panoptic_head.pixel_decoder.input_convs.0.conv.weight------>torch.Size([256, 1536, 1, 1])
panoptic_head.pixel_decoder.input_convs.0.conv.bias------>torch.Size([256])
panoptic_head.pixel_decoder.input_convs.0.ln.weight------>torch.Size([256])
panoptic_head.pixel_decoder.input_convs.0.ln.bias------>torch.Size([256])
panoptic_head.pixel_decoder.input_convs.1.conv.weight------>torch.Size([256, 768, 1, 1])
panoptic_head.pixel_decoder.input_convs.1.conv.bias------>torch.Size([256])
panoptic_head.pixel_decoder.input_convs.1.ln.weight------>torch.Size([256])
panoptic_head.pixel_decoder.input_convs.1.ln.bias------>torch.Size([256])
panoptic_head.pixel_decoder.input_convs.2.conv.weight------>torch.Size([256, 384, 1, 1])
panoptic_head.pixel_decoder.input_convs.2.conv.bias------>torch.Size([256])
panoptic_head.pixel_decoder.input_convs.2.ln.weight------>torch.Size([256])
panoptic_head.pixel_decoder.input_convs.2.ln.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
panoptic_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias------>torch.Size([192])
panoptic_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight------>torch.Size([96, 256])
panoptic_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias------>torch.Size([96])
panoptic_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight------>torch.Size([1024, 256])
panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias------>torch.Size([1024])
panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight------>torch.Size([256, 1024])
panoptic_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.0.norms.0.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.0.norms.0.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.0.norms.1.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.0.norms.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
panoptic_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias------>torch.Size([192])
panoptic_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight------>torch.Size([96, 256])
panoptic_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias------>torch.Size([96])
panoptic_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight------>torch.Size([1024, 256])
panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias------>torch.Size([1024])
panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight------>torch.Size([256, 1024])
panoptic_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.1.norms.0.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.1.norms.0.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.1.norms.1.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.1.norms.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
panoptic_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias------>torch.Size([192])
panoptic_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight------>torch.Size([96, 256])
panoptic_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias------>torch.Size([96])
panoptic_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight------>torch.Size([1024, 256])
panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias------>torch.Size([1024])
panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight------>torch.Size([256, 1024])
panoptic_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.2.norms.0.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.2.norms.0.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.2.norms.1.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.2.norms.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
panoptic_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias------>torch.Size([192])
panoptic_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight------>torch.Size([96, 256])
panoptic_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias------>torch.Size([96])
panoptic_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight------>torch.Size([1024, 256])
panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias------>torch.Size([1024])
panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight------>torch.Size([256, 1024])
panoptic_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.3.norms.0.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.3.norms.0.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.3.norms.1.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.3.norms.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
panoptic_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias------>torch.Size([192])
panoptic_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight------>torch.Size([96, 256])
panoptic_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias------>torch.Size([96])
panoptic_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight------>torch.Size([1024, 256])
panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias------>torch.Size([1024])
panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight------>torch.Size([256, 1024])
panoptic_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.4.norms.0.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.4.norms.0.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.4.norms.1.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.4.norms.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
panoptic_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias------>torch.Size([192])
panoptic_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight------>torch.Size([96, 256])
panoptic_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias------>torch.Size([96])
panoptic_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight------>torch.Size([256, 256])
panoptic_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight------>torch.Size([1024, 256])
panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias------>torch.Size([1024])
panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight------>torch.Size([256, 1024])
panoptic_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.5.norms.0.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.5.norms.0.bias------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.5.norms.1.weight------>torch.Size([256])
panoptic_head.pixel_decoder.encoder.layers.5.norms.1.bias------>torch.Size([256])
panoptic_head.pixel_decoder.level_encoding.weight------>torch.Size([3, 256])
panoptic_head.pixel_decoder.lateral_convs.0.conv.weight------>torch.Size([256, 192, 1, 1])
panoptic_head.pixel_decoder.lateral_convs.0.ln.weight------>torch.Size([256])
panoptic_head.pixel_decoder.lateral_convs.0.ln.bias------>torch.Size([256])
panoptic_head.pixel_decoder.output_convs.0.conv.weight------>torch.Size([256, 256, 3, 3])
panoptic_head.pixel_decoder.output_convs.0.ln.weight------>torch.Size([256])
panoptic_head.pixel_decoder.output_convs.0.ln.bias------>torch.Size([256])
panoptic_head.pixel_decoder.mask_feature.weight------>torch.Size([256, 256, 1, 1])
panoptic_head.pixel_decoder.mask_feature.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.0.ffn.layers.0.0.weight------>torch.Size([2048, 256])
panoptic_head.transformer_decoder.layers.0.ffn.layers.0.0.bias------>torch.Size([2048])
panoptic_head.transformer_decoder.layers.0.ffn.layers.1.weight------>torch.Size([256, 2048])
panoptic_head.transformer_decoder.layers.0.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.0.norms.0.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.0.norms.0.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.0.norms.1.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.0.norms.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.0.norms.2.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.0.norms.2.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.1.ffn.layers.0.0.weight------>torch.Size([2048, 256])
panoptic_head.transformer_decoder.layers.1.ffn.layers.0.0.bias------>torch.Size([2048])
panoptic_head.transformer_decoder.layers.1.ffn.layers.1.weight------>torch.Size([256, 2048])
panoptic_head.transformer_decoder.layers.1.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.1.norms.0.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.1.norms.0.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.1.norms.1.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.1.norms.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.1.norms.2.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.1.norms.2.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.2.ffn.layers.0.0.weight------>torch.Size([2048, 256])
panoptic_head.transformer_decoder.layers.2.ffn.layers.0.0.bias------>torch.Size([2048])
panoptic_head.transformer_decoder.layers.2.ffn.layers.1.weight------>torch.Size([256, 2048])
panoptic_head.transformer_decoder.layers.2.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.2.norms.0.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.2.norms.0.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.2.norms.1.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.2.norms.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.2.norms.2.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.2.norms.2.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.3.ffn.layers.0.0.weight------>torch.Size([2048, 256])
panoptic_head.transformer_decoder.layers.3.ffn.layers.0.0.bias------>torch.Size([2048])
panoptic_head.transformer_decoder.layers.3.ffn.layers.1.weight------>torch.Size([256, 2048])
panoptic_head.transformer_decoder.layers.3.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.3.norms.0.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.3.norms.0.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.3.norms.1.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.3.norms.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.3.norms.2.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.3.norms.2.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.4.ffn.layers.0.0.weight------>torch.Size([2048, 256])
panoptic_head.transformer_decoder.layers.4.ffn.layers.0.0.bias------>torch.Size([2048])
panoptic_head.transformer_decoder.layers.4.ffn.layers.1.weight------>torch.Size([256, 2048])
panoptic_head.transformer_decoder.layers.4.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.4.norms.0.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.4.norms.0.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.4.norms.1.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.4.norms.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.4.norms.2.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.4.norms.2.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.5.ffn.layers.0.0.weight------>torch.Size([2048, 256])
panoptic_head.transformer_decoder.layers.5.ffn.layers.0.0.bias------>torch.Size([2048])
panoptic_head.transformer_decoder.layers.5.ffn.layers.1.weight------>torch.Size([256, 2048])
panoptic_head.transformer_decoder.layers.5.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.5.norms.0.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.5.norms.0.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.5.norms.1.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.5.norms.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.5.norms.2.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.5.norms.2.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.6.ffn.layers.0.0.weight------>torch.Size([2048, 256])
panoptic_head.transformer_decoder.layers.6.ffn.layers.0.0.bias------>torch.Size([2048])
panoptic_head.transformer_decoder.layers.6.ffn.layers.1.weight------>torch.Size([256, 2048])
panoptic_head.transformer_decoder.layers.6.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.6.norms.0.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.6.norms.0.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.6.norms.1.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.6.norms.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.6.norms.2.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.6.norms.2.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.7.ffn.layers.0.0.weight------>torch.Size([2048, 256])
panoptic_head.transformer_decoder.layers.7.ffn.layers.0.0.bias------>torch.Size([2048])
panoptic_head.transformer_decoder.layers.7.ffn.layers.1.weight------>torch.Size([256, 2048])
panoptic_head.transformer_decoder.layers.7.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.7.norms.0.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.7.norms.0.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.7.norms.1.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.7.norms.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.7.norms.2.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.7.norms.2.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias------>torch.Size([768])
panoptic_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.8.ffn.layers.0.0.weight------>torch.Size([2048, 256])
panoptic_head.transformer_decoder.layers.8.ffn.layers.0.0.bias------>torch.Size([2048])
panoptic_head.transformer_decoder.layers.8.ffn.layers.1.weight------>torch.Size([256, 2048])
panoptic_head.transformer_decoder.layers.8.ffn.layers.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.8.norms.0.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.8.norms.0.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.8.norms.1.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.8.norms.1.bias------>torch.Size([256])
panoptic_head.transformer_decoder.layers.8.norms.2.weight------>torch.Size([256])
panoptic_head.transformer_decoder.layers.8.norms.2.bias------>torch.Size([256])
panoptic_head.transformer_decoder.post_norm.weight------>torch.Size([256])
panoptic_head.transformer_decoder.post_norm.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.0.self_attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.class_transformer.decoder.layers.0.self_attn.in_proj_bias------>torch.Size([768])
panoptic_head.class_transformer.decoder.layers.0.self_attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.class_transformer.decoder.layers.0.self_attn.out_proj.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.0.multihead_attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.class_transformer.decoder.layers.0.multihead_attn.in_proj_bias------>torch.Size([768])
panoptic_head.class_transformer.decoder.layers.0.multihead_attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.class_transformer.decoder.layers.0.multihead_attn.out_proj.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.0.linear1.weight------>torch.Size([2048, 256])
panoptic_head.class_transformer.decoder.layers.0.linear1.bias------>torch.Size([2048])
panoptic_head.class_transformer.decoder.layers.0.linear2.weight------>torch.Size([256, 2048])
panoptic_head.class_transformer.decoder.layers.0.linear2.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.0.norm1.weight------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.0.norm1.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.0.norm2.weight------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.0.norm2.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.0.norm3.weight------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.0.norm3.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.1.self_attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.class_transformer.decoder.layers.1.self_attn.in_proj_bias------>torch.Size([768])
panoptic_head.class_transformer.decoder.layers.1.self_attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.class_transformer.decoder.layers.1.self_attn.out_proj.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.1.multihead_attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.class_transformer.decoder.layers.1.multihead_attn.in_proj_bias------>torch.Size([768])
panoptic_head.class_transformer.decoder.layers.1.multihead_attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.class_transformer.decoder.layers.1.multihead_attn.out_proj.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.1.linear1.weight------>torch.Size([2048, 256])
panoptic_head.class_transformer.decoder.layers.1.linear1.bias------>torch.Size([2048])
panoptic_head.class_transformer.decoder.layers.1.linear2.weight------>torch.Size([256, 2048])
panoptic_head.class_transformer.decoder.layers.1.linear2.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.1.norm1.weight------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.1.norm1.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.1.norm2.weight------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.1.norm2.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.1.norm3.weight------>torch.Size([256])
panoptic_head.class_transformer.decoder.layers.1.norm3.bias------>torch.Size([256])
panoptic_head.class_transformer.decoder.norm.weight------>torch.Size([256])
panoptic_head.class_transformer.decoder.norm.bias------>torch.Size([256])
panoptic_head.task_mlp.layers.0.weight------>torch.Size([256, 77])
panoptic_head.task_mlp.layers.0.bias------>torch.Size([256])
panoptic_head.task_mlp.layers.1.weight------>torch.Size([256, 256])
panoptic_head.task_mlp.layers.1.bias------>torch.Size([256])
panoptic_head.decoder_norm.weight------>torch.Size([256])
panoptic_head.decoder_norm.bias------>torch.Size([256])
panoptic_head.class_input_proj.weight------>torch.Size([256, 256, 1, 1])
panoptic_head.class_input_proj.bias------>torch.Size([256])
panoptic_head.query_embed.weight------>torch.Size([150, 256])
panoptic_head.level_embed.weight------>torch.Size([3, 256])
panoptic_head.cls_embed.weight------>torch.Size([134, 256])
panoptic_head.cls_embed.bias------>torch.Size([134])
panoptic_head.mask_embed.0.weight------>torch.Size([256, 256])
panoptic_head.mask_embed.0.bias------>torch.Size([256])
panoptic_head.mask_embed.2.weight------>torch.Size([256, 256])
panoptic_head.mask_embed.2.bias------>torch.Size([256])
panoptic_head.mask_embed.4.weight------>torch.Size([256, 256])
panoptic_head.mask_embed.4.bias------>torch.Size([256])
panoptic_head.text_encoder.positional_embedding------>torch.Size([77, 256])
panoptic_head.text_encoder.transformer.resblocks.0.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.text_encoder.transformer.resblocks.0.attn.in_proj_bias------>torch.Size([768])
panoptic_head.text_encoder.transformer.resblocks.0.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.text_encoder.transformer.resblocks.0.attn.out_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.0.ln_1.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.0.ln_1.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.0.mlp.c_fc.weight------>torch.Size([1024, 256])
panoptic_head.text_encoder.transformer.resblocks.0.mlp.c_fc.bias------>torch.Size([1024])
panoptic_head.text_encoder.transformer.resblocks.0.mlp.c_proj.weight------>torch.Size([256, 1024])
panoptic_head.text_encoder.transformer.resblocks.0.mlp.c_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.0.ln_2.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.0.ln_2.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.1.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.text_encoder.transformer.resblocks.1.attn.in_proj_bias------>torch.Size([768])
panoptic_head.text_encoder.transformer.resblocks.1.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.text_encoder.transformer.resblocks.1.attn.out_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.1.ln_1.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.1.ln_1.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.1.mlp.c_fc.weight------>torch.Size([1024, 256])
panoptic_head.text_encoder.transformer.resblocks.1.mlp.c_fc.bias------>torch.Size([1024])
panoptic_head.text_encoder.transformer.resblocks.1.mlp.c_proj.weight------>torch.Size([256, 1024])
panoptic_head.text_encoder.transformer.resblocks.1.mlp.c_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.1.ln_2.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.1.ln_2.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.2.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.text_encoder.transformer.resblocks.2.attn.in_proj_bias------>torch.Size([768])
panoptic_head.text_encoder.transformer.resblocks.2.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.text_encoder.transformer.resblocks.2.attn.out_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.2.ln_1.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.2.ln_1.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.2.mlp.c_fc.weight------>torch.Size([1024, 256])
panoptic_head.text_encoder.transformer.resblocks.2.mlp.c_fc.bias------>torch.Size([1024])
panoptic_head.text_encoder.transformer.resblocks.2.mlp.c_proj.weight------>torch.Size([256, 1024])
panoptic_head.text_encoder.transformer.resblocks.2.mlp.c_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.2.ln_2.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.2.ln_2.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.3.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.text_encoder.transformer.resblocks.3.attn.in_proj_bias------>torch.Size([768])
panoptic_head.text_encoder.transformer.resblocks.3.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.text_encoder.transformer.resblocks.3.attn.out_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.3.ln_1.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.3.ln_1.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.3.mlp.c_fc.weight------>torch.Size([1024, 256])
panoptic_head.text_encoder.transformer.resblocks.3.mlp.c_fc.bias------>torch.Size([1024])
panoptic_head.text_encoder.transformer.resblocks.3.mlp.c_proj.weight------>torch.Size([256, 1024])
panoptic_head.text_encoder.transformer.resblocks.3.mlp.c_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.3.ln_2.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.3.ln_2.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.4.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.text_encoder.transformer.resblocks.4.attn.in_proj_bias------>torch.Size([768])
panoptic_head.text_encoder.transformer.resblocks.4.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.text_encoder.transformer.resblocks.4.attn.out_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.4.ln_1.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.4.ln_1.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.4.mlp.c_fc.weight------>torch.Size([1024, 256])
panoptic_head.text_encoder.transformer.resblocks.4.mlp.c_fc.bias------>torch.Size([1024])
panoptic_head.text_encoder.transformer.resblocks.4.mlp.c_proj.weight------>torch.Size([256, 1024])
panoptic_head.text_encoder.transformer.resblocks.4.mlp.c_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.4.ln_2.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.4.ln_2.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.5.attn.in_proj_weight------>torch.Size([768, 256])
panoptic_head.text_encoder.transformer.resblocks.5.attn.in_proj_bias------>torch.Size([768])
panoptic_head.text_encoder.transformer.resblocks.5.attn.out_proj.weight------>torch.Size([256, 256])
panoptic_head.text_encoder.transformer.resblocks.5.attn.out_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.5.ln_1.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.5.ln_1.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.5.mlp.c_fc.weight------>torch.Size([1024, 256])
panoptic_head.text_encoder.transformer.resblocks.5.mlp.c_fc.bias------>torch.Size([1024])
panoptic_head.text_encoder.transformer.resblocks.5.mlp.c_proj.weight------>torch.Size([256, 1024])
panoptic_head.text_encoder.transformer.resblocks.5.mlp.c_proj.bias------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.5.ln_2.weight------>torch.Size([256])
panoptic_head.text_encoder.transformer.resblocks.5.ln_2.bias------>torch.Size([256])
panoptic_head.text_encoder.ln_final.weight------>torch.Size([256])
panoptic_head.text_encoder.ln_final.bias------>torch.Size([256])
panoptic_head.text_encoder.token_embedding.weight------>torch.Size([49408, 256])
panoptic_head.text_projector.layers.0.weight------>torch.Size([256, 256])
panoptic_head.text_projector.layers.0.bias------>torch.Size([256])
panoptic_head.text_projector.layers.1.weight------>torch.Size([256, 256])
panoptic_head.text_projector.layers.1.bias------>torch.Size([256])
panoptic_head.prompt_ctx.weight------>torch.Size([16, 256])
