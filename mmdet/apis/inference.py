# Copyright (c) OpenMMLab. All rights reserved.
import warnings
from pathlib import Path

import mmcv
import numpy as np
import torch
from mmcv.ops import RoIPool
from mmcv.parallel import collate, scatter
from mmcv.runner import load_checkpoint

from mmdet.core import get_classes
from mmdet.datasets import replace_ImageToTensor
from mmdet.datasets.pipelines import Compose
from mmdet.models import build_detector


def init_detector(config, checkpoint=None, device='cuda:0', cfg_options=None):
    """从配置文件初始化检测模型.

    Args:
        config (str, :obj:`Path`, or :obj:`mmcv.Config`): 配置文件路径,或配置对象.
        checkpoint (str, optional): 权重路径. 如果为None, 模型不会加载任何权重.
        cfg_options (dict): 覆盖所用配置中的某些设置的选项.

    Returns:
        nn.Module: 初始化后的检测模型.
    """
    if isinstance(config, (str, Path)):
        config = mmcv.Config.fromfile(config)
    elif not isinstance(config, mmcv.Config):
        raise TypeError('config must be a filename or Config object, '
                        f'but got {type(config)}')
    if cfg_options is not None:
        config.merge_from_dict(cfg_options)
    if 'pretrained' in config.model:
        config.model.pretrained = None
    elif 'init_cfg' in config.model.backbone:
        config.model.backbone.init_cfg = None
    config.model.train_cfg = None  # 避免构建只在train才使用的方法,assigner, sampler等
    model = build_detector(config.model)
    if checkpoint is not None:
        checkpoint = load_checkpoint(model, checkpoint, map_location='cpu')
        if 'CLASSES' in checkpoint.get('meta', {}):
            model.CLASSES = checkpoint['meta']['CLASSES']
        else:
            warnings.simplefilter('once')
            warnings.warn('加载的权重中不存在类别列表,默认使用COCO类.')
            model.CLASSES = get_classes('coco')  # 初始化为coco的80类
    model.cfg = config  # 为方便起见,将配置保存在模型中
    model.to(device)
    model.eval()

    if device == 'npu':
        from mmcv.device.npu import NPUDataParallel
        model = NPUDataParallel(model)
        model.cfg = config

    return model


class LoadImage:
    """Deprecated.

    A simple pipeline to load image.
    """

    def __call__(self, results):
        """Call function to load images into results.

        Args:
            results (dict): A result dict contains the file name
                of the image to be read.
        Returns:
            dict: ``results`` will be returned containing loaded image.
        """
        warnings.simplefilter('once')
        warnings.warn('`LoadImage` is deprecated and will be removed in '
                      'future releases. You may use `LoadImageFromWebcam` '
                      'from `mmdet.datasets.pipelines.` instead.')
        if isinstance(results['img'], str):
            results['filename'] = results['img']
            results['ori_filename'] = results['img']
        else:
            results['filename'] = None
            results['ori_filename'] = None
        img = mmcv.imread(results['img'])
        results['img'] = img
        results['img_fields'] = ['img']
        results['img_shape'] = img.shape
        results['ori_shape'] = img.shape
        return results


def inference_detector(model, imgs):
    """使用检测模型推理单(多)幅图像.

    Args:
        model (nn.Module): 已加载的检测器模型.
        imgs (str/ndarray or list[str/ndarray] or tuple[str/ndarray]):
           图像文件路径或已加载的numpy数据,可为单个str/np 或者[str/np,]/(str/np,).

    Returns:
        如果 imgs 是列表或元组, 则返回相同长度的列表类型结果, 否则直接返回检测结果.
    """

    if isinstance(imgs, (list, tuple)):
        is_batch = True
    else:
        imgs = [imgs]
        is_batch = False

    cfg = model.cfg
    device = next(model.parameters()).device  # model device

    if isinstance(imgs[0], np.ndarray):
        cfg = cfg.copy()
        # 如果参数img是numpy型数据,那么切换数据加载方式
        cfg.data.test.pipeline[0].type = 'LoadImageFromWebcam'

    cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)
    test_pipeline = Compose(cfg.data.test.pipeline)

    datas = []
    for img in imgs:
        # 准备数据,当img为numpy数据时,代表它已是无需加载的
        if isinstance(img, np.ndarray):
            # 直接添加img
            data = dict(img=img)
        else:
            # 否则需要通过LoadImageFromFile来从路径中加载图片
            data = dict(img_info=dict(filename=img), img_prefix=None)
        # build the data pipeline
        data = test_pipeline(data)
        datas.append(data)
    # 将多张图片整合到一起, 包括兼容不同长宽比的图片至同一尺寸
    # 注! 它是将所有测试图片揉到一个batch中,只跑一遍inference.
    data = collate(datas, samples_per_gpu=len(imgs))
    # {'img_metas':[DC([]),], 'img':[DC[tensor(bs, 3, 480, 640),],]}
    # 最外面的[]是TTA数量,里面的[]中的数据是GPU数量的数据,TTA与bs不能同时大于1
    # inference_detector 默认单卡推理,所以DC包裹的列表长度为1
    # 此处的.data[0]意为从DataContainer(.data)获取第一张卡([0])的数据
    data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]
    data['img'] = [img.data[0] for img in data['img']]
    if next(model.parameters()).is_cuda:
        # 将数据分配到指定的 GPU
        data = scatter(data, [device])[0]
    else:
        for m in model.modules():
            assert not isinstance(
                m, RoIPool
            ), 'CPU inference with RoIPool is not supported currently.'

    # 对模型前向传播
    with torch.no_grad():
        results = model(return_loss=False, rescale=True, **data)

    if not is_batch:
        return results[0]
    else:
        return results


async def async_inference_detector(model, imgs):
    """Async inference image(s) with the detector.

    Args:
        model (nn.Module): The loaded detector.
        img (str | ndarray): Either image files or loaded images.

    Returns:
        Awaitable detection results.
    """
    if not isinstance(imgs, (list, tuple)):
        imgs = [imgs]

    cfg = model.cfg
    device = next(model.parameters()).device  # model device

    if isinstance(imgs[0], np.ndarray):
        cfg = cfg.copy()
        # set loading pipeline type
        cfg.data.test.pipeline[0].type = 'LoadImageFromWebcam'

    cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)
    test_pipeline = Compose(cfg.data.test.pipeline)

    datas = []
    for img in imgs:
        # prepare data
        if isinstance(img, np.ndarray):
            # directly add img
            data = dict(img=img)
        else:
            # add information into dict
            data = dict(img_info=dict(filename=img), img_prefix=None)
        # build the data pipeline
        data = test_pipeline(data)
        datas.append(data)

    data = collate(datas, samples_per_gpu=len(imgs))
    # just get the actual data from DataContainer
    data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]
    data['img'] = [img.data[0] for img in data['img']]
    if next(model.parameters()).is_cuda:
        # scatter to specified GPU
        data = scatter(data, [device])[0]
    else:
        for m in model.modules():
            assert not isinstance(
                m, RoIPool
            ), 'CPU inference with RoIPool is not supported currently.'

    # We don't restore `torch.is_grad_enabled()` value during concurrent
    # inference since execution can overlap
    torch.set_grad_enabled(False)
    results = await model.aforward_test(rescale=True, **data)
    return results


def show_result_pyplot(model,
                       img,
                       result,
                       score_thr=0.3,
                       title='result',
                       wait_time=0,
                       palette=None,
                       out_file=None):
    """在图像上绘制检测结果.

    Args:
        model (nn.Module): 加载的检测模型.
        img (str or np.ndarray): 图像文件名或加载的图像数据.
        result (tuple[list] or list): 检测结果,(bbox, segm) or bbox
        score_thr (float): boxes 和 mask 的置信度显示阈值.
        title (str): 图像展示窗口的标题.
        wait_time (float): waitKey 参数的值. 默认为: 0ms.意为无限等待
        palette (str or tuple(int) or :obj:`Color`): 颜色, 如果是元组应按 BGR 顺序.
        out_file (str or None): 图片保存的路径.
            Default: None.
    """
    if hasattr(model, 'module'):
        model = model.module
    model.show_result(
        img,
        result,
        score_thr=score_thr,
        show=True,
        wait_time=wait_time,
        win_name=title,
        bbox_color=palette,
        text_color=(200, 200, 200),
        mask_color=palette,
        out_file=out_file)
